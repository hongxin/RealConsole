# Phase 7 性能优化计划

**日期**: 2025-10-16
**目标**: 大文件日志分析加速（目标：1GB < 3s）

## 性能瓶颈分析

### 1. 正则表达式重复编译（最严重）⚠️

**问题**:
- `detect_level()`: 每次调用编译 9 个正则表达式
- `extract_timestamp()`: 每次调用编译 3 个正则表达式
- `extract_message()`: 每次调用编译 2 个正则表达式
- `extract_error_pattern()`: 每次调用编译 4 个正则表达式

**影响**:
- 对于 100 万行日志，编译 1800 万次正则表达式
- 估计耗时：~80% 的总运行时间

**解决方案**: 使用 `once_cell::sync::Lazy` 缓存编译好的正则表达式

### 2. 所有错误保存在内存中 ⚠️

**问题**:
- `analysis.errors.push(entry)` - 保存所有错误
- `analysis.warnings.push(entry)` - 保存所有警告
- 每个 `LogEntry` 包含完整的行内容（`raw_content`）

**影响**:
- 对于有 10 万个错误的文件，内存占用可能达到 GB 级别

**解决方案**:
- 限制保存的错误数量（例如：前 100 个 + 最后 100 个）
- 只保存摘要信息，不保存完整行内容

### 3. read_tail 效率低 ⚠️

**问题**:
- 读取整个文件只为了获取最后 N 行

**影响**:
- 对于 1GB 文件，即使只要最后 50 行也需要读取整个文件

**解决方案**:
- 使用文件 seek 从末尾向前读取
- 或者接受当前实现（因为使用场景较少）

## 优化实施计划

### 阶段 1: 正则表达式缓存 ✅ 进行中

**优先级**: 🔴 最高
**预期提升**: 5-10倍性能提升
**工期**: 1小时

**实施步骤**:
1. ✅ 添加 `once_cell` 依赖
2. 创建全局正则表达式缓存
3. 重构 `detect_level()` 使用缓存
4. 重构 `extract_timestamp()` 使用缓存
5. 重构 `extract_message()` 使用缓存
6. 重构 `extract_error_pattern()` 使用缓存
7. 测试验证性能提升

### 阶段 2: 内存优化

**优先级**: 🟡 中
**预期提升**: 减少 80% 内存占用
**工期**: 30分钟

**实施步骤**:
1. 添加 `max_errors` 和 `max_warnings` 参数
2. 实现循环缓冲区（保留前N个和最后N个）
3. 简化 `LogEntry` 结构（可选保存 `raw_content`）

### 阶段 3: 大文件采样分析

**优先级**: 🟡 中
**预期提升**: 对超大文件（>100MB）提速 10-100倍
**工期**: 1小时

**实施步骤**:
1. 检测文件大小
2. 对于 > 100MB 的文件，采样分析（每隔 N 行）
3. 在结果中标注是否为采样分析
4. 添加 `--full` 参数强制完整分析

### 阶段 4: 性能基准测试

**优先级**: 🟢 低
**预期提升**: 建立性能基线
**工期**: 30分钟

**实施步骤**:
1. 创建测试日志文件（1K、10K、100K、1M 行）
2. 使用 `criterion` 添加性能基准测试
3. 记录优化前后性能对比

## 性能目标

### 当前性能（估计）

| 文件大小 | 行数 | 预估耗时 | 内存占用 |
|---------|------|---------|---------|
| 1MB | 10K | ~0.5s | ~5MB |
| 10MB | 100K | ~5s | ~50MB |
| 100MB | 1M | ~50s | ~500MB |
| 1GB | 10M | ~500s (8分钟) | ~5GB |

### 优化后目标

| 文件大小 | 行数 | 目标耗时 | 内存占用 |
|---------|------|---------|---------|
| 1MB | 10K | < 0.1s | < 1MB |
| 10MB | 100K | < 0.5s | < 10MB |
| 100MB | 1M | < 3s | < 50MB |
| 1GB | 10M | < 3s (采样) | < 50MB |
| 1GB | 10M | < 30s (完整) | < 100MB |

## 实施顺序

1. **先做阶段 1（正则缓存）** - 影响最大
2. **再做阶段 2（内存优化）** - 解决大文件问题
3. **最后做阶段 3（采样分析）** - 处理超大文件
4. **完成阶段 4（基准测试）** - 验证效果

## 成功指标

- ✅ 正则表达式只编译一次
- ✅ 10万行日志分析 < 0.5s
- ✅ 100万行日志分析 < 3s
- ✅ 内存占用 < 100MB（无论文件大小）
- ✅ 所有现有测试通过

---

**最后更新**: 2025-10-16
**状态**: 🔵 进行中（阶段 1）
